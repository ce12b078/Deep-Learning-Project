{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrktlKwVtLtZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bd442cc4-09b4-4efc-9601-4175456ec98d"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiByXqmItTpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxwQBcritTrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import LearningRateScheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agkITM44tTuZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "70f77276-c7cd-4c6e-9039-778e63e690fa"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5Vh1hrQtT2c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2051f102-ac82-41c4-a391-14cf1a0c2085"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train,y_train), (x_test,y_test) = mnist.load_data()\n",
        "\n",
        "x_train = np.array(x_train)\n",
        "print(x_train.shape)\n",
        "\n",
        "x_test = np.array(x_test)\n",
        "print(x_test.shape)\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "print(y_train.shape)\n",
        "\n",
        "y_test = np.array(y_test)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "(60000,)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFGhD7V7tnJe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0229ffa0-27b9-4a2b-932d-4a566e216e40"
      },
      "source": [
        "x_train = x_train.reshape(60000, 28, 28, 1)\n",
        "x_test = x_test.reshape(10000, 28, 28, 1)\n",
        "\n",
        "x_train = x_train.astype(\"float32\")/255.\n",
        "x_test = x_test.astype(\"float32\")/255\n",
        "\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "#example:\n",
        "print(y_train[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwfGP9w0tn_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#******************************************************\n",
        "#Without batch normalisation, training time is much higher **********************************************\n",
        "#**************************************************\n",
        "\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',input_shape = (28, 28, 1)))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
        "#model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer = Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Import model checkpoint from keras callbacks\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Instantiate a model checkpoint callback\n",
        "model_save = ModelCheckpoint('best_model.hdf5',\n",
        "save_best_only=True)\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "validation_split=0.2, epochs=20, verbose=2, batch_size=64, \n",
        "callbacks = [model_save])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZbvzO6ttoIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.callbacks import EarlyStopping\n",
        "# Instantiate an early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=2)\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu',input_shape = (28, 28, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 16, kernel_size = (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer = Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "# Import model checkpoint from keras callbacks\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Instantiate a model checkpoint callback\n",
        "model_save = ModelCheckpoint('best_model.hdf5',\n",
        "save_best_only=True)\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "validation_split=0.2, epochs=20, verbose=2, batch_size=64, \n",
        "callbacks = [model_save,early_stopping])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aD2SjFgBtoLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}